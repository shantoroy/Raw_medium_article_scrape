{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing All Stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "from post_details import PostDetais\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for collecting post contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostDetais(object):\n",
    "    def __init__(self, soup, link=None):\n",
    "        self.page_soup = soup\n",
    "        self.link = link\n",
    "\n",
    "    def get_title(self):\n",
    "        class_names = ['jz b ka kh ay',\n",
    "                       'graf graf--h3 graf--leading graf--title',\n",
    "                       'graf graf--h3 graf-after--figure graf--trailing graf--title']\n",
    "        try:\n",
    "            for my_tag in self.page_soup.find_all(True, {\n",
    "                                                    'class': class_names}):\n",
    "                title = my_tag.text\n",
    "                return title\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_title\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\"\n",
    "\n",
    "    def get_author_name(self):\n",
    "        class_names = \"ck cl cm cn co cp cq cr cs ct jm cw cx cy cz\"\n",
    "        try:\n",
    "            for my_tag in self.page_soup.find_all(\n",
    "                    class_=class_names):\n",
    "                name = my_tag.text\n",
    "                return name\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_title\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\"\n",
    "\n",
    "    def get_date(self):\n",
    "        class_names = 'ck cl cm cn co cp cq cr cs ct jm cw cx cy cz'\n",
    "        try:\n",
    "            for my_tag in self.page_soup.find_all(class_names):\n",
    "                date_time = my_tag.text\n",
    "                return date_time\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_title\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\"\n",
    "\n",
    "    def get_read(self):\n",
    "        try:\n",
    "            for my_tag in self.page_soup.find_all(class_=\"readingTime\"):\n",
    "                read = my_tag.get('title')\n",
    "                return read\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_title\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\"\n",
    "\n",
    "    def get_upvote(self):\n",
    "        class_names = 'u-relative u-background js-actionMultirecommendCount u-marginLeft5'\n",
    "        try:\n",
    "            for my_tag in self.page_soup.find_all('span', {\n",
    "                'class': class_names}):\n",
    "                upvotes = my_tag.text\n",
    "                return upvotes\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_upvote\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\"\n",
    "\n",
    "    def get_body(self):\n",
    "        news_body = \"\"\n",
    "        for paragraphs in self.page_soup.find_all(\n",
    "                class_='graf graf--p graf-after--p'):\n",
    "            news_body += paragraphs.text.rstrip().lstrip()\n",
    "        return news_body\n",
    "\n",
    "    def get_post_content(self):\n",
    "        try:\n",
    "            # class_=\"section-content\"\n",
    "            # we are using <article> tag as section-content class no longer works\n",
    "            # everything is inside the article tag including title & author names\n",
    "            for content in self.page_soup.find_all('article'):\n",
    "                return content.text\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_post_content\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\"\n",
    "\n",
    "    def get_response(self):\n",
    "        class_names = 'button button--chromeless u-baseColor--buttonNormal u-marginRight12'\n",
    "        try:\n",
    "            class_names = 'button button--chromeless u-baseColor--buttonNormal u-marginRight12'\n",
    "            for my_tag in self.page_soup.find_all('button', {\n",
    "                'class': class_names}):\n",
    "                res = my_tag.text\n",
    "                return res\n",
    "        except Exception as e:\n",
    "            error_trace = {}\n",
    "            error_trace[\"link\"] = self.link\n",
    "            error_trace[\"method\"] = \"get_response\"\n",
    "            error_trace[\"message\"] = str(e)\n",
    "            print(json.dumps(error_trace, indent=4))\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class for Scrapping pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediumScrapper(object):\n",
    "    def __init__(self, CHROME_DRIVER_PATH='/home/mrx/Downloads/chromedriver'):\n",
    "        self.CHROME_DRIVER_PATH = CHROME_DRIVER_PATH\n",
    "        content = self.get_intial_content()\n",
    "        self.parsed_data = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "    def get_intial_content(self,\n",
    "                           base_url=\"https://medium.com/search?q=ethereum\"):\n",
    "        driver = webdriver.Chrome(self.CHROME_DRIVER_PATH)\n",
    "        driver.get(base_url)\n",
    "        scrolls = 1\n",
    "        while scrolls > 0:\n",
    "            driver.execute_script(\n",
    "                \"window.scrollTo(0, document.body.scrollHeight-1000);\")\n",
    "            time.sleep(10)\n",
    "            scrolls -= 1\n",
    "        # driver.implicitly_wait(30)\n",
    "        time.sleep(10)\n",
    "        content = driver.execute_script(\n",
    "            \"return document.documentElement.outerHTML\")\n",
    "        driver.quit()\n",
    "        return content\n",
    "\n",
    "    def get_post_links(self):\n",
    "        links = []\n",
    "        class_names = \"button button--smaller button--chromeless u-baseColor--buttonNormal\"\n",
    "        for my_tag in self.parsed_data.find_all(class_=class_names):\n",
    "            links.append(my_tag.get('href'))\n",
    "        return links\n",
    "\n",
    "    def get_post_contents(self):\n",
    "        links = self.get_post_links()\n",
    "        data = []\n",
    "        headers = requests.utils.default_headers()\n",
    "        headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
    "        })\n",
    "        for link in links:\n",
    "            try:\n",
    "                print(\"Scrapping link: {}\".format(link))\n",
    "                time.sleep(15)\n",
    "                request_link = requests.get(link, headers=headers)\n",
    "                request_content = BeautifulSoup(request_link.content,\n",
    "                                                'html.parser')\n",
    "                post_details = PostDetais(request_content, link)\n",
    "                post_title = post_details.get_title()\n",
    "                author_name = post_details.get_author_name()\n",
    "                post_date = post_details.get_date()\n",
    "                post_readtime = post_details.get_read()\n",
    "                post_upvotes = post_details.get_upvote()\n",
    "                post_contents = post_details.get_post_content()\n",
    "                post_responses = post_details.get_response()\n",
    "                single_post = {\n",
    "                    \"title\": post_title,\n",
    "                    \"author_name\": author_name,\n",
    "                    \"link\": link,\n",
    "                    \"post_date\": post_date,\n",
    "                    \"readtime\": post_readtime,\n",
    "                    \"upvotes\": post_upvotes,\n",
    "                    \"content\": post_contents,\n",
    "                    \"responses\": post_responses\n",
    "                }\n",
    "                data.append(single_post)\n",
    "            except Exception as e:\n",
    "                print(\"Error in scrapping link: {}\".format(link))\n",
    "                print(str(e))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping link: https://medium.com/@preethikasireddy/how-does-ethereum-work-anyway-22d1df506369?source=search_post---------0\n",
      "Scrapping link: https://medium.com/hackernoon/neo-versus-ethereum-why-neo-might-be-2018s-strongest-cryptocurrency-79956138bea3?source=search_post---------1\n",
      "Scrapping link: https://medium.com/free-code-camp/a-hacker-stole-31m-of-ether-how-it-happened-and-what-it-means-for-ethereum-9e5dc29e33ce?source=search_post---------2\n",
      "Scrapping link: https://medium.com/hackernoon/ethereum-will-pass-bitcoin-in-2018-my-cryptocurrency-investment-portfolio-dcab52905bba?source=search_post---------3\n",
      "Scrapping link: https://medium.com/hackernoon/cardano-ethereum-and-neo-killer-or-overhyped-and-overpriced-8fcd5f8abcdf?source=search_post---------4\n",
      "Scrapping link: https://medium.com/loom-network/ethereum-will-be-the-backbone-of-the-new-internet-88718e08124f?source=search_post---------5\n",
      "Scrapping link: https://blog.coinbase.com/ethereum-classic-etc-is-currently-being-51-attacked-33be13ce32de?source=search_post---------6\n",
      "Scrapping link: https://blog.coinbase.com/a-beginners-guide-to-ethereum-46dd486ceecf?source=search_post---------7\n",
      "Scrapping link: https://medium.com/@ethereumlimited/ethereum-limited-private-sale-procedure-9401b7188841?source=search_post---------8\n",
      "Scrapping link: https://medium.com/hackernoon/the-ethereum-blockchain-size-has-exceeded-1tb-and-yes-its-an-issue-2b650b5f4f62?source=search_post\n",
      "Scrapping link: https://blog.enjincoin.io/announcing-enjinx-ad-free-user-friendly-ethereum-blockchain-explorer-3d679ba034c8?source=search_post\n",
      "Scrapping link: https://medium.com/startup-grind/i-was-wrong-about-ethereum-804c9a906d36?source=search_post\n",
      "Scrapping link: https://medium.com/@mvmurthy/full-stack-hello-world-voting-ethereum-dapp-tutorial-part-1-40d2d0d807c2?source=search_post\n",
      "Scrapping link: https://medium.com/hackernoon/bitcoin-ethereum-blockchain-tokens-icos-why-should-anyone-care-890b868cec06?source=search_post\n",
      "Scrapping link: https://blog.coinbase.com/ethereum-is-the-forefront-of-digital-currency-5300298f6c75?source=search_post\n",
      "Scrapping link: https://media.consensys.net/the-state-of-the-ethereum-network-949332cb6895?source=search_post\n",
      "Scrapping link: https://medium.com/bitfwd/how-to-issue-your-own-token-on-ethereum-in-less-than-20-minutes-ac1f8f022793?source=search_post\n",
      "Scrapping link: https://medium.com/@ConsenSys/a-101-noob-intro-to-programming-smart-contracts-on-ethereum-695d15c1dab4?source=search_post\n",
      "Scrapping link: https://medium.com/swipecrypto/inaugural-keynote-digix-and-ethereum-singapore-ecb341ff1446?source=search_post\n",
      "Check JSON file: test5.json\n",
      "Total posts: 19\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    scrapper = MediumScrapper()\n",
    "    output_filename = 'test5.json'\n",
    "    data = scrapper.get_post_contents()\n",
    "    with open(output_filename, 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "    print(\"Check JSON file: {}\".format(output_filename))\n",
    "    print(\"Total posts: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "file_name = \"test5.json\"\n",
    "with open(file_name, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(data[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
