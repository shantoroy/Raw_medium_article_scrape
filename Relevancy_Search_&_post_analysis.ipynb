{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import operator\n",
    "import string\n",
    "\n",
    "\n",
    "# Class to append value in a dictionary\n",
    "class MyDictionary(dict):\n",
    "\n",
    "    # __init__ function\n",
    "    def __init__(self):\n",
    "        self = dict()\n",
    "\n",
    "    # Function to add key:value\n",
    "    def add(self, key, value):\n",
    "        self[key] = value\n",
    "\n",
    "\n",
    "class Relevancy(object):\n",
    "    def __init__(self, file_name, tag):\n",
    "        self.tag = tag\n",
    "        self.file_name = file_name\n",
    "        with open(self.file_name, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    # Python3 code to pre-processing the string\n",
    "    # Intending to remove all punctuation and common words\n",
    "    def pre_process(self, str):\n",
    "        # removing punctuation ---> using string module\n",
    "        translator = str.maketrans('', '', string.punctuation)\n",
    "        str = str.translate(translator)\n",
    "\n",
    "        # converting all into lower cases\n",
    "        str = str.lower()\n",
    "        \n",
    "        # removing numbers and digits\n",
    "        # str = ''.join([i for i in str if not i.isdigit()])\n",
    "        regex = re.compile('[^a-zA-Z]')\n",
    "        #First parameter is the replacement, second parameter is your input string\n",
    "        str = regex.sub(' ', str)\n",
    "\n",
    "        # removing prep, conj, articles ---> using re module\n",
    "        str = re.sub('(\\s+)(a|an|and|the|this|that|these|those|i|would|could|should|m|ve)(\\s+)', ' ', str)\n",
    "        str = re.sub('(\\s+)(to|for|from|in|into|under|with|within|below|up|down|of|on|s|t)(\\s+)', ' ', str)\n",
    "        str = re.sub('(\\s+)(are|may|by|as|we|or|it|be|which|the|when|make|no|set|your|its|it\\'s)(\\s+)', ' ', str)\n",
    "        str = re.sub('(\\s+)(if|any|used|all|has|have|new|data|at|code|node|state|-|they|our)(\\s+)', ' ', str)\n",
    "        str = re.sub('(\\s+)(you|must|every|each|not|what|one|then|way|so|will|also|is|can|\"|\")(\\s+)', ' ', str)\n",
    "        str = re.sub('(\\s+)(their|was|more|other|use|do|need|my|some|get|out|many|had|here|over)(\\s+)', ' ', str)\n",
    "        return str\n",
    "\n",
    "    # Python3 code to find frequency of each word\n",
    "    # function for calculating the frequency\n",
    "    def freq(self, str):\n",
    "        str = self.pre_process(str)\n",
    "\n",
    "        # break the string into list of words\n",
    "        str_list = str.split()\n",
    "\n",
    "        # gives set of unique words\n",
    "        unique_words = set(str_list)\n",
    "        frequency = MyDictionary()\n",
    "        for word in unique_words:\n",
    "            frequency.add(word, str_list.count(word))\n",
    "\n",
    "        # sort by value (downwards) ---> using operator module\n",
    "        sorted_freq = sorted(frequency.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "        # collect first 10 items in dictionary\n",
    "        # first_few_items = {k: sorted_freq[k] for k in list(sorted_freq)[:10]}\n",
    "        # btw, sorted_freq is a list\n",
    "        return sorted_freq[0:20]  # , len(sorted_freq)\n",
    "\n",
    "    # merge two lists toether without appending same word\n",
    "    # if same word found, increases count\n",
    "    def merge_two_lists(self, a, b):\n",
    "        new_list = {}\n",
    "        for pair in a + b:\n",
    "            key, value = pair\n",
    "            new_list[key] = new_list.get(key, 0) + value\n",
    "        new_list = [[key, value] for key, value in new_list.items()]\n",
    "        return new_list\n",
    "\n",
    "    # convert a tuple into a list\n",
    "    def tuple_to_list(self, listname):\n",
    "        a = []\n",
    "        for i in range(0, len(listname)):\n",
    "            a.append(list(listname[i]))\n",
    "        return a\n",
    "\n",
    "    # For sorting a list of lists using 2nd item\n",
    "    def second_item(self, item):\n",
    "        return item[1]\n",
    "\n",
    "    # for getting a list of words for a particular tag\n",
    "    def list_of_most_used_words(self):\n",
    "        freq_list = []\n",
    "        for key in self.data:\n",
    "            if self.tag in key['title'].lower():\n",
    "                str = key['content']\n",
    "                freq_list = self.merge_two_lists(freq_list, self.tuple_to_list(self.freq(str)))\n",
    "\n",
    "        freq_list.sort(key=self.second_item, reverse=True)\n",
    "        reduced_list = []\n",
    "        for i in freq_list:\n",
    "            if i[1] > 1000:\n",
    "                reduced_list.append(i)\n",
    "        return reduced_list\n",
    "\n",
    "    # Return number of Relevant posts\n",
    "    def relevant_post(self):\n",
    "        relevant = 0\n",
    "        for key in self.data:\n",
    "            if self.tag in key['title'].lower():\n",
    "                relevant += 1\n",
    "        return relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Relevant post is:373\n",
      "[['ethereum', 4558], ['blockchain', 1641], ['contract', 1259], ['but', 1057]]\n"
     ]
    }
   ],
   "source": [
    "# application code\n",
    "if __name__ == \"__main__\":\n",
    "    file_name = \"ethereum.json\"\n",
    "    tag = 'ethereum'\n",
    "    keyword = Relevancy(file_name, tag)\n",
    "    print(\"Number of Relevant post is:\" + str(keyword.relevant_post()))\n",
    "    print(keyword.list_of_most_used_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevancy Search in percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from math import floor\n",
    "count = 0\n",
    "file_name = \"data/ethereum.json\"\n",
    "with open(file_name, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "relevant = 0\n",
    "for key in data:\n",
    "    if 'ethereum' in key['title'].lower():\n",
    "        relevant += 1\n",
    "for key in data:\n",
    "    count += 1      \n",
    "p = floor(relevant/count * 100)\n",
    "print(relevant)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better relevancy search using finding tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482\n",
      "485\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from math import floor\n",
    "count = 0\n",
    "file_name = \"data/ethereum.json\"\n",
    "with open(file_name, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "relevant = 0\n",
    "for key in data:\n",
    "    count += 1\n",
    "    tags = key['tags']\n",
    "    for item in tags: \n",
    "        if 'ethereum' in item.lower():\n",
    "            relevant += 1\n",
    "print(relevant)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input all relevant posts into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "final_count = 0\n",
    "final_json_data = []\n",
    "\n",
    "file_name_list = [\"ethereum.json\", \"blockchain.json\", \"smart-contract.json\",\n",
    "                      \"solidity.json\", \"vyper.json\", \"ripple.json\",\n",
    "                      \"remix.json\", \"metamask.json\", \"bitcoin.json\"]\n",
    "tag_list = [\"ethereum\", \"blockchain\", \"smart contract\", \"solidity\", \"vyper\", \"ripple\",\n",
    "                \"remix\", \"metamask\", \"bitcoin\"]\n",
    "\n",
    "for file_name, tag in zip(file_name_list, tag_list):\n",
    "\n",
    "    json_data  = json.load(open(filename))\n",
    "\n",
    "    for key in json_data:\n",
    "        tags = key['tags']\n",
    "        for item in tags: \n",
    "            if tag in item.lower():\n",
    "                final_json_data.append(key)\n",
    "                count += 1\n",
    "    print(\"Number of total post for \", tag, \"is =\", count)\n",
    "\n",
    "    # Output the updated file with pretty JSON                                      \n",
    "open(\"final_all_post_data.json\", \"w\").write(\n",
    "        json.dumps(final_json_data, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "    )\n",
    "print(\"The number of total post is: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"ename\": [\"mark\", \"egg\"], \"url\": \"Lennon.com\"}, {\"ename\": [\"egg\"], \"url\": \"Lennon.com\"}]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data  = json.load(open(\"_test_.json\"))\n",
    "new = []\n",
    "\n",
    "for key in data:\n",
    "    count += 1\n",
    "    tags = key['ename']\n",
    "    for item in tags: \n",
    "        if 'egg' in item.lower():\n",
    "            new.append(key)\n",
    "\n",
    "new = json.dumps(new)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_tag = {\"ethereum-390.json\":\"ethereum\", \"vyper-272.json\":\"vyper\",\n",
    "                \"bitcoin-281.json\":\"bitcoin\", \"smart-contract-369\":\"smart contract\",\n",
    "                \"blockchain-351.json\":\"blockchain\", \"solidity-374\":\"solidity\"}\n",
    "for x,y in file_tag.items():\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posts over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2019': 5,\n",
       " '2018': 3,\n",
       " '2017': 1,\n",
       " '2016': 2,\n",
       " '2015': 1,\n",
       " '2014': 0,\n",
       " 'missing': 2}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year_list = ['2019', '2018', '2017', '2016', '2015', '2014']\n",
    "#month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "            # 'August', 'September', 'October', 'November', 'December']\n",
    "freq = {\"2019\":0, \"2018\":0, \"2017\":0, \"2016\":0, \"2015\":0, \"2014\":0, \"missing\":0}\n",
    "date_list = ['27 April, 2018', '17 December', '12 May, 2017', '17 January',\n",
    "            '16 June, 2018', '16 April', '', '16 April', '11 May, 2016', '', '17 June, 2018',\n",
    "             '11 May, 2016', '27 April, 2015', '16 April']\n",
    "for date in date_list:\n",
    "    if ',' in date:\n",
    "        y = date.split(',')[1]\n",
    "        y = y.lstrip()\n",
    "        freq[y] += 1\n",
    "    elif date=='':\n",
    "        freq[\"missing\"] += 1\n",
    "    else:\n",
    "        freq[\"2019\"] += 1\n",
    "        \n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016', '11', '27']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '2016-11-27'\n",
    "a = a.split(\"-\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panda DataFrame for Medium Posts\n",
    "file_name = \"metamask-350.json\"\n",
    "dates = []\n",
    "with open(file_name, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(data, orient='columns')\n",
    "#df[['post_date', 'upvotes']]\n",
    "for key in data:\n",
    "    dates.append(key['post_date'])\n",
    "if dates[26]=='':\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Bala', 'phone': 'None'}, {'Name': 'Bala1', 'phone': 'None'}]\n"
     ]
    }
   ],
   "source": [
    "te = [\n",
    "      {\n",
    "        \"Name\": \"Bala\",\n",
    "        \"phone\": \"None\"\n",
    "      },\n",
    "      {\n",
    "        \"Name\": \"Bala\",\n",
    "        \"phone\": \"None\"\n",
    "      },\n",
    "      {\n",
    "        \"Name\": \"Bala\",\n",
    "        \"phone\": \"None\"\n",
    "      },\n",
    "      {\n",
    "        \"Name\": \"Bala\",\n",
    "        \"phone\": \"None\"\n",
    "      },\n",
    "      {\n",
    "          \"Name\": \"Bala1\",\n",
    "          \"phone\": \"None\"\n",
    "      }      \n",
    "    ]\n",
    "\n",
    "unique = { each['Name'] : each for each in te }\n",
    "a = list(unique.values())\n",
    "with open(\"test_3.json\",\"w\") as fp:\n",
    "    json.dump(a, fp)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of post after removing duplicay =  2156\n"
     ]
    }
   ],
   "source": [
    "with open(\"final_all_post_data.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "unique_post = {each['title'] : each for each in data}\n",
    "listed_dictionary_items = list(unique_post.values())\n",
    "with open(\"final_data_removing_duplicacy.json\",\"w\") as f:\n",
    "    json.dump(listed_dictionary_items, f)\n",
    "print(\"# of post after removing duplicay = \", len(listed_dictionary_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associative Tag analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12840\n",
      "1732\n",
      "Counter({'Smart Contracts': 5424, 'Ethereum': 3907, 'Blockchain': 3635, 'Solidity': 1840, 'Security': 1399, 'Cryptocurrency': 610, 'Audit': 449, 'Bitcoin': 381, 'ICO': 322, 'Tutorial': 309, 'Erc20': 230, 'Dapps': 229, 'Truffle': 226, 'Programming': 223, 'Technology': 194, 'Web3': 173, 'Development': 163, 'Token Sale': 133, 'Blockchain Technology': 124, 'Crypto': 123, 'Smart Contract Security': 112, 'Token': 94, 'Blockchain Development': 94, 'Decentralization': 85, 'Fintech': 80, 'Ethereum Blockchain': 73, 'Tech': 65, 'Insurance': 60, 'Tech Blog': 60, 'Cryptography': 59, 'Startup': 55, 'Hacking': 54, 'Neo': 54, 'Eos': 54, 'Cybersecurity': 54, 'JavaScript': 53, 'Open Source': 50, 'Vulnerability': 50, 'Vyper': 44, 'Remix': 42, 'Software Development': 40, 'Real Estate': 40, 'Quantstamp': 40, 'Security Audit': 40, 'Tokenization': 40, 'Legaltech': 39, 'Finance': 39, 'Smart Contract Auditing': 38, 'Openzeppelin': 35, 'Smart Contracts Tutorial': 35, 'Solidity Tutorial': 35, 'Coding': 34, 'Innovation': 33, 'Metamask': 33, 'Formal Verification': 31, 'Law': 30, 'Gochain': 30, 'Crowdsale': 30, '이더리움': 30, '솔리디티': 30, 'Security Token': 30, 'Testing': 28, 'IoT': 25, 'Decentralized': 25, 'Research': 25, 'Investing': 25, 'Solidity 102': 25, 'Distributed Ledgers': 24, 'Bug Bounty': 24, 'Security Audits': 21, 'Partnerships': 20, 'Developer Tools': 20, 'Privacy': 20, 'Eth': 20, 'Legal': 20, 'Reverse Engineering': 20, 'Ether': 20, 'Blockchain Education': 20, 'Gas': 20, 'Decentralized Apps': 20, 'Blockchain Security': 20, 'Certikaudits': 20, 'Security Tokens': 20, 'Geth': 19, 'Rsk': 19, 'Crowdfunding': 19, 'Consensys': 19, 'Smart Contract Blockchain': 19, 'Eosio': 17, 'Nodejs': 16, 'Oracle': 15, 'Programming Languages': 15, 'Marketplaces': 15, 'Contracts': 15, 'Guide': 15, 'Governance': 15, 'Altcoins': 15, 'Aeternity': 15, 'Team': 15, 'News': 15, 'Visual Studio': 15, 'Developer': 15, 'Constantinople': 15, 'AI': 15, 'Future': 15, 'Events': 15, 'Zeppelin': 15, 'Evm': 15, 'Mathematics': 15, 'Debugging': 15, 'Joyso': 15, 'Joyso Chinese': 15, 'Ganache': 15, 'Decentralized Exchange': 15, 'Hosho': 15, 'Information Security': 15, 'Sto': 15, 'Stellar': 14, 'Dispute Resolutions': 14, 'Etherparty': 14, 'Database': 14, 'Gaming': 14, 'Randomness': 14, 'Application Security': 14, 'Unit Testing': 12, 'Certikrock': 12, '區塊鏈': 10, 'Ethereum Smart Contracts': 10, 'Python': 10, 'Upgradeable': 10, 'Product Management': 10, 'Java': 10, 'Hello World': 10, 'Proof Of Stake': 10, 'Justice': 10, 'Brickblock': 10, 'English': 10, 'Mywish': 10, 'Software Engineering': 10, 'API': 10, 'Kadena': 10, 'Stable Coin': 10, 'Trading': 10, 'Transparency': 10, 'Engineering': 10, 'Thedao': 10, 'Enterprise Technology': 10, 'Developers': 10, 'Artificial Intelligence': 10, 'Waves': 10, 'Hyperledger': 10, 'Makerdao': 10, 'Platform': 10, 'Education': 10, 'Coinpoker': 10, 'Internet of Things': 10, 'Entrepreneurship': 10, 'Infographics': 10, 'Financial Services': 10, 'Payments': 10, 'Ecommerce': 10, 'Healthcare': 10, 'Investment': 10, 'Digital Transformation': 10, 'University': 10, 'NPM': 10, 'Golang': 10, 'Eclipse': 10, 'Oraclize': 10, 'Ganache Cli': 10, 'Infura': 10, 'Deployment': 10, 'Blog': 10, 'Adoption': 10, 'Penetration Testing': 10, 'Annoucements': 10, 'Mythx': 10, 'Haechi Labs': 10, 'Venture Capital': 10, 'Token Economy': 10, 'Social Media': 10, 'Smartphones': 10, 'Blockchain Application': 10, 'Hyperledger Fabric': 10, 'Firewall': 10, 'Github': 9, 'Truth': 9, 'Rsksmart': 9, 'Qtum': 9, 'Beginner': 9, 'Islamic Finance': 9, 'Bounty Program': 9, 'Zero Knowledge Proofs': 9, 'Escrow': 9, 'Taipei': 9, 'Peckshield': 9, 'Private Blockchain': 8, 'Appcoins': 8, 'Tor': 8, 'Newsletter': 8, 'Iota': 7, 'Future Of Work': 5, '智能合約': 5, 'Reentrancy Attack': 5, 'Python Smart Contracts': 5, 'Upgradable': 5, 'Prototyping': 5, 'Qubic': 5, 'Deploy Smart Contracts': 5, 'Bitcoincash': 5, 'Smart Contract Platforms': 5, 'Contractpedia': 5, 'Honeypot': 5, 'Stellar Lumens': 5, 'Functional Programming': 5, 'Dapp Developers': 5, 'Dapp Development': 5, 'Ethereum Development': 5, 'Cryptocurrencies': 5, 'Steampunk': 5, 'Language Design': 5, 'Smart Cities': 5, 'Simplicity': 5, 'What Are Smart Contracts': 5, 'Eip 999': 5, 'Content Creation': 5, 'Myetherwallet': 5, 'Bef': 5, 'Whitelist': 5, 'Evolive': 5, 'Evopro': 5, 'Ideafex': 5, 'Wallet': 5, 'Btc': 5, 'Comparison': 5, 'Hackernoon Top Story': 5, 'Custody': 5, 'Videocoin': 5, 'Videos': 5, 'Social Networks': 5, 'Aepps': 5, 'Blockchain Smart Contract': 5, 'Smart Contract Pitfalls': 5, 'Case Study': 5, 'Chain Link': 5, 'Crytpocurrencies': 5, 'Public Blockchain': 5, 'Columbia University': 5, 'Pchain': 5, 'Environmental Issues': 5, 'Democracy': 5, 'Voting': 5, 'Blockchain Público': 5, 'Inmobilliaria': 5, 'Dapp': 5, 'The Dao': 5, 'Censorship': 5, 'Gifto': 5, 'Uplive': 5, 'Asia Innovations Group': 5, 'Slack': 5, 'Yee Token': 5, 'Yee': 5, 'Yeecall': 5, 'Technews': 5, 'Content Marketing': 5, 'Interledger': 5, 'Web Hosting': 5, 'Subjectivity': 5, 'Risk Taking': 5, 'Smart Contracts Explained': 5, 'To My 10 Year Old': 5, 'Kimex': 5, 'Binary Options': 5, 'Kmx': 5, 'Sports Betting': 5, 'Story': 5, 'Beginnerscoinbundle': 5, 'Tether': 5, 'Ethlend': 5, 'Interview Questions': 5, 'Game Theory': 5, 'Typescript': 5, 'Atomic Swaps': 5, 'Legal Services': 5, 'Polkadot Network': 5, 'Cosmos Network': 5, 'Editorials': 5, 'Tezos': 5, 'Insights': 5, 'Upgrade': 5, 'Mainnet': 5, 'Matrix': 5, 'Bugs': 5, 'Distributed Systems': 5, 'Iulia': 5, 'Lll': 5, 'Opinion': 5, 'Hyperledger Sawtooth': 5, 'Blockchain Business': 5, 'Best Smart Contracts': 5, 'Lawyers': 5, 'Dev': 5, 'Csharp': 5, 'Encryption': 5, 'Green Energy': 5, 'Environment': 5, 'Learning To Code': 5, 'Versioned Contracts': 5, 'Upgradable Contracts': 5, 'Treaty Contracts': 5, 'Construction': 5, 'Openlaw': 5, 'Ethereum Solidity': 5, 'Algorithms': 5, 'Consensus Mechanisms': 5, 'State Channels': 5, 'Podcast': 5, 'Bitdegree': 5, 'Bounty': 5, 'Code Audit': 5, 'Use Cases': 5, 'Jargon': 5, 'Sovereignty': 5, 'Liquid Democracy': 5, 'Blockchains': 5, 'Democracy Ambassadors': 5, 'Paymon': 5, 'Hive': 5, 'Blockcerts': 5, 'Apps': 5, 'Cars': 5, 'Hackernoon Podcast': 5, 'Product Updates': 5, 'Marketing Automation': 5, 'Marketing': 5, 'Marketing Strategies': 5, 'Bch': 5, 'Steemit': 5, 'Regtech': 5, 'Regulation': 5, 'Dreamteam': 5, 'Testnet': 5, 'Tokens': 5, 'Industry Insights': 5, 'Rubius': 5, 'Open Government': 5, 'Lending': 5, 'Genesis Vision': 5, 'Real Estate Investments': 5, 'Financing': 5, 'Featured': 5, 'Media': 5, 'Promotion': 5, 'Commerce': 5, 'Recruitment': 5, 'Metahash': 5, 'Banking': 5, 'Gig Economy': 5, 'Smartrealty': 5, 'Real Estate Transactions': 5, 'Bankers Rounding': 5, 'Reddit': 5, 'Blockchanneltv': 5, 'Blockchannel': 5, 'Disruption': 5, 'Credits Dev Portal': 5, 'Automation': 5, 'Analysis': 5, 'Sweetbridge Academy': 5, 'Dsl': 5, 'Domain Specific Languages': 5, 'Industrial Revolution': 5, 'Koreconx': 5, 'Eth Network': 5, 'Data': 5, 'Loans': 5, 'Policy Management': 5, 'Property Management': 5, 'Telegram': 5, 'CEO': 5, 'Libraries': 5, 'Public Functions': 5, 'External Functions': 5, 'Best Practices': 5, 'Guides And Tutorials': 5, 'Guides': 5, 'Plasma': 5, 'Scalability': 5, 'Kvm': 5, 'Testrpc': 5, 'Occupy Wall Street': 5, 'T7': 5, 'Sevilla': 5, 'Proptech': 5, 'Defi': 5, 'Data Storage': 5, 'Data Structures': 5, 'Formal Analysis': 5, 'Solidity Tutorials': 5, 'Windows 10': 5, 'Metacoin': 5, 'Continuous Integration': 5, 'Türkçe': 5, 'Ixledger Updates': 5, 'Intellij': 5, 'Enum': 5, 'Developing': 5, 'Ivy': 5, 'Technicals': 5, 'Tomochain': 5, 'Transaction Ordering': 5, 'Ethereum Classic': 5, 'Oráculos': 5, 'Random': 5, 'Ethereum Virtual Machine': 5, 'Accounting': 5, 'Bumo': 5, 'State Machine': 5, 'Relationships': 5, 'Web3js': 5, 'Distributed Applications': 5, 'Barcamp': 5, 'Community': 5, 'Assert': 5, 'Español': 5, 'Solidity Language': 5, 'Import': 5, 'React Native': 5, 'Expo': 5, 'Learning': 5, 'Atom': 5, 'Struts': 5, 'Logs': 5, 'Computer Science': 5, 'Smart Contacts Tutorial': 5, 'React': 5, 'Automated Testing': 5, 'Online Courses': 5, 'Test Driven Development': 5, 'Chromebook': 5, 'Linux': 5, 'Blockchain Programming': 5, 'GraphQL': 5, 'Erc721': 5, 'Zeppelinos': 5, 'Web3j': 5, '以太坊': 5, 'Internet': 5, 'Web3py': 5, '中文': 5, 'Identity': 5, 'Hackernoon': 5, 'Angular 5': 5, 'Uniswap': 5, 'Interfaces': 5, 'Ide': 5, 'Adex': 5, 'Neo Tokens': 5, 'Citowise': 5, 'Bitnautic': 5, 'Xrt': 5, 'Howtobuidl': 5, 'Buidl': 5, 'Exploitation': 5, 'Tbh Stories': 5, 'Fleta': 5, 'Gnosis': 5, 'Coinbase': 5, 'Alan Turing': 5, 'Turing Test': 5, 'Formal Proofs': 5, 'Security Services': 5, 'Security Guards': 5, 'Fysical': 5, 'Enterprise': 5, 'Cybr': 5, 'Zmine': 5, 'Ontology': 5, 'Synthetic Minds': 5, 'Program Synthesis': 5, 'Conference': 5, 'Certik': 5, 'Alliances': 5, 'Auditing': 5, 'Amazix': 5, 'Solar Dao': 5, 'Every Token': 5, 'Crypto Valley': 5, 'Unchained Capital': 5, 'Games': 5, 'Zero Trust': 5, 'Utrust': 5, 'Exploit': 5, 'Visa': 5, 'Stacktical': 5, 'Alibaba': 5, 'Carry Protocol': 5, 'Fomo3d': 5, 'Smart Contracts Audit': 5, 'Request Network': 5, 'Fuzzing': 5, 'Nick Szabo': 5, 'Certikclass': 5, 'Market Network': 5, 'Property Rights': 5, 'Blockchain Economics': 5, 'Report': 5, 'Hacken': 5, 'Sonm': 5, 'Validation': 5, 'Disclosure': 5, 'Design Thinking': 5, 'Enecuum': 5, 'Oracles': 5, 'Hacks': 5, 'Japan': 5, 'Bancor': 5, 'Parity Wallet Hack': 5, 'Dating': 5, 'Blockchain Tech': 5, 'Cyber Attacks': 5, 'Storj': 5, 'Security Certifications': 5, 'Enterprise Blockchain': 5, 'Higher Education': 5, 'Data Security': 5, 'Risk Management': 5, 'Product': 5, 'Homepage': 5, 'Trail Of Bits': 5, 'Smart Contracts Testing': 5, 'Enterprise Security': 5, 'Web Security': 5, 'Security Analysis': 5, 'Automated': 5, 'Releases': 5, 'Coinpoint': 5, 'Daostack': 5, 'Fault Tolerance': 5, 'Machine Learning': 5, 'Assets': 5, 'Formal Methods': 5, 'Heritage': 5, 'Static Code Analysis': 5, 'Cisco': 5, 'Verification': 5, 'Certiknews': 5, 'Dxdao': 5, 'Rust': 5, 'Opensourceuniversity': 5, 'Etherum': 5, 'Hoshocon': 5, 'C Programming': 5, 'Decentralized Insurance': 5, 'Business': 5, 'Cryptocurrency Investment': 5, 'Blockbase': 5, 'Token Estate': 5, 'Solium': 5, 'Proof Of Toss': 5, 'Betting Protocol': 5, 'Cybermiles': 5, 'E Commerce Business': 5, 'Intel': 5, 'Fujitsu': 5, 'Climate Change': 5, 'Environmental Litigation': 5, 'Dao Ipci': 5, 'Pharmaceutical': 5, 'Supply Chain': 5, 'Land Rights': 5, 'Rustlang': 5, 'Openrelay': 5, 'Key Management': 5, 'Usability': 5, 'Batchoverflow': 5, 'Huobi': 5, 'IBM': 5, 'Blockchain Solution': 5, 'Bermuda': 5, 'Financial Inclusion': 5, 'Iotw': 5, 'Developer Relations': 5, 'Fundraising': 5, 'Protocol': 5, 'Chainlink': 5, 'Switcheo': 5, 'Cloud Storage': 5, 'Cloud Computing': 5, 'Cloud': 5, 'Tzero': 5, 'Ternion': 4, 'Operating Systems': 4, 'Universa': 4, 'Universa Education': 4, 'Zerion': 4, 'Hackathons': 4, 'Rewards': 4, 'Flint': 4, 'Technical': 4, 'Legislation': 4, 'Student Voices': 4, 'Aseet Token': 4, 'Smart Token': 4, 'Fiduciary': 4, 'Asset Management': 4, 'Airdrop': 4, 'Electrical Engineering': 4, 'Chronologic': 4, 'Customer Success': 4, 'Droit': 4, 'France': 4, 'Economies': 4, 'Dotnet': 4, 'Cheatsheet': 4, 'Ethers': 4, 'Hack': 4, 'Foodtech': 4, 'Erc': 4, 'Trinity': 4, 'Embark': 4, 'Maian': 4, 'Plugins': 4, 'Smart Contract Bug': 4, 'Checklist': 4, 'Publication': 4, 'Mithril': 4, 'Eth Zurich': 4, 'Loyalty': 4, 'Airlines': 4, 'Thekey': 3, 'Virtual Machine': 3, 'Crosschain': 3, 'Music': 3, 'Streaming Music': 3, 'Ardor': 3, 'It Security': 3, 'Omisego': 3})\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../conference_medium_data/new_data/related_data_rm_duplicacy_conf_final_2.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "count = 0\n",
    "tag_list = []\n",
    "for key in data:\n",
    "    tag_list.append([i for i in key['tags']])\n",
    "    count += 1\n",
    "\n",
    "# 2 ways to remove nested lists\n",
    "from itertools import chain\n",
    "break_nested_list = list(chain(*tag_list))\n",
    "print(len(break_nested_list))\n",
    "# flattened  = [val for sublist in list_of_lists for val in sublist]\n",
    "unique_list_of_tags = list(set(break_nested_list))\n",
    "print(len(unique_list_of_tags))\n",
    "\n",
    "from collections import Counter\n",
    "associated_with_tag = list(set([item for items in tag_list if \"Solidity\" in items for item in items]))\n",
    "top_tags_for_tag = Counter([item for items in tag_list if \"Solidity\" in items for item in items])\n",
    "\n",
    "top_tags_only = Counter([item for items in tag_list for item in items])\n",
    "\n",
    "associated_with_smart_contract = list(set([item for items in tag_list if \"Smart Contracts\"\\\n",
    "                                           in items for item in items or \"Smart Contract\" in items for item in items]))\n",
    "top_tags_for_smart_contracts = Counter(([item for items in tag_list if \"Smart Contracts\"\\\n",
    "                                           in items for item in items or \"Smart Contract\" in items for item in items]))\n",
    "#print(associated_with_tag)\n",
    "print(top_tags_for_smart_contracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag frequency count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solidity = 854\n",
      "ethereum = 1860\n",
      "blockchain = 1657\n",
      "web3 = 377\n",
      "metamask = 296\n",
      "truffle = 181\n",
      "remix = 14\n",
      "token = 70\n",
      "tokens = 3\n",
      "erc20 = 425\n",
      "vyper = 26\n",
      "smart contract = 40\n",
      "smart contracts = 1145\n",
      "ethereum blockchain = 57\n",
      "myetherwallet = 22\n",
      "wallet = 28\n",
      "dapp = 9\n",
      "dapps = 174\n",
      "security = 352\n",
      "decentralization = 94\n",
      "bitcoin = 172\n",
      "cryptocurrency = 345\n",
      "audit = 101\n",
      "ico = 158\n",
      "token sale = 60\n",
      "blockchain technology = 65\n",
      "decentralization = 94\n",
      "crypto = 63\n",
      "ethereum blockchain = 57\n",
      "blockchain development = 52\n",
      "programming = 113\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../conference_medium_data/new_data/related_data_rm_duplicacy_conf_final_2.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "tag_list = [\"solidity\", \"ethereum\", \"blockchain\", \"web3\", \"metamask\", \"truffle\", \"remix\", \"token\",\\\n",
    "            \"tokens\", \"erc20\", \"vyper\", \"smart contract\", \"smart contracts\", \"ethereum blockchain\",\\\n",
    "            \"myetherwallet\", \"wallet\", \"dapp\", \"dapps\", \"security\", \"decentralization\", \"bitcoin\",\\\n",
    "            \"cryptocurrency\", \"audit\", \"ico\", \"token sale\", \"blockchain technology\", \"decentralization\",\\\n",
    "            \"crypto\", \"ethereum blockchain\", \"blockchain development\", \"programming\"]\n",
    "\n",
    "for i in tag_list:\n",
    "    count = 0\n",
    "    for key in data:\n",
    "        if i in [item.lower() for item in key['tags']]:\n",
    "            count += 1\n",
    "            # print(key['title'])\n",
    "    print(i, \"=\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2760\n",
      "Average=  1.857246376811594\n",
      "[(0, 1726), (1, 417), (2, 194), (3, 119), (4, 63), (5, 55), (7, 28), (8, 28), (6, 26), (9, 20), (11, 14), (10, 12), (12, 9), (14, 5), (16, 5), (21, 4), (17, 3), (23, 3), (13, 3), (39, 2), (18, 2), (136, 2), (146, 2), (153, 1), (68, 1), (24, 1), (19, 1), (22, 1), (79, 1), (20, 1), (29, 1), (40, 1), (72, 1), (165, 1), (105, 1), (63, 1), (131, 1), (57, 1), (26, 1), (15, 1), (140, 1)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../conference_medium_data/new_data/related_data_rm_duplicacy_conf_final_2.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "response_list = []\n",
    "for key in data:\n",
    "    response_list.append(key['responses'])\n",
    "    count += 1\n",
    "response_freq = Counter([item for item in response_list])\n",
    "print(len(response_list))\n",
    "print(\"Average= \", sum(response_list)/len(response_list))\n",
    "print(response_freq.most_common())\n",
    "# print(sorted(response_list, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg claps and voters for individual tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solidity --> 1491 & 1.65 & 258005 & 286.35 & 26794 & 29.74\n",
      "Web3 --> 765 & 1.8 & 194111 & 457.81 & 18066 & 42.61\n",
      "Ethereum --> 4358 & 2.21 & 800054 & 406.33 & 78924 & 40.08\n",
      "Truffle --> 259 & 1.11 & 24371 & 104.15 & 2772 & 11.85\n",
      "Security --> 469 & 0.98 & 99980 & 209.16 & 8666 & 18.13\n",
      "Metamask --> 237 & 0.79 & 67243 & 224.89 & 5298 & 17.72\n",
      "Remix --> 15 & 0.94 & 2178 & 136.12 & 212 & 13.25\n",
      "Ethereum Blockchain --> 113 & 1.98 & 47661 & 836.16 & 2878 & 50.49\n",
      "Blockchain --> 3415 & 1.8 & 833901 & 440.05 & 72145 & 38.07\n",
      "Myetherwallet --> 12 & 0.55 & 2976 & 135.27 & 172 & 7.82\n",
      "Erc20 --> 1511 & 3.39 & 378248 & 848.09 & 23398 & 52.46\n",
      "Token Sale --> 191 & 3.18 & 30373 & 506.22 & 1628 & 27.13\n",
      "Cryptocurrency --> 732 & 2.02 & 240544 & 664.49 & 16842 & 46.52\n",
      "Bitcoin --> 815 & 4.58 & 165487 & 929.7 & 18009 & 101.17\n",
      "Ico --> 0 & 0.0 & 253 & 84.33 & 33 & 11.0\n",
      "ICO --> 920 & 5.82 & 147425 & 933.07 & 8803 & 55.72\n",
      "Programming --> 172 & 1.38 & 41225 & 329.8 & 4005 & 32.04\n",
      "Audit --> 52 & 0.36 & 21217 & 146.32 & 1558 & 10.74\n",
      "Decentralization --> 160 & 1.7 & 49254 & 523.98 & 3645 & 38.78\n",
      "Crypto --> 1077 & 2.29 & 290282 & 616.31 & 20877 & 44.32\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "with open(\"../conference_medium_data/new_data/related_data_rm_duplicacy_conf_final_2.json\",\"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "clap_list = []\n",
    "voter_list = []\n",
    "data_dict = dict()\n",
    "for key in data:\n",
    "    clap_list.append(key['claps'])\n",
    "    voter_list.append(key['voters'])\n",
    "for i,j in zip(clap_list,voter_list):\n",
    "    data_dict[i] = j\n",
    "\n",
    "def resp_clap_voter_1(data, tag):\n",
    "    new_clap = []\n",
    "    new_voter = []\n",
    "    new_response = []\n",
    "    for key in data:\n",
    "        for i in key['tags']:\n",
    "            if tag in i:\n",
    "                new_clap.append(key['claps'])\n",
    "                new_voter.append(key['voters'])\n",
    "                new_response.append(key['responses'])\n",
    "    \n",
    "    max_response = max(new_response)\n",
    "    total_response = sum(new_response)\n",
    "    avg_response = sum(new_response)/len(new_response)\n",
    "    \n",
    "    max_clap = max(new_clap)\n",
    "    total_clap = sum(new_clap)\n",
    "    avg_clap = sum(new_clap)/len(new_clap)\n",
    "    \n",
    "    max_voter = max(new_voter)\n",
    "    total_voter = sum(new_voter)\n",
    "    avg_voter = sum(new_voter)/len(new_voter)\n",
    "    \n",
    "    return total_response, round(avg_response,2), total_clap, round(avg_clap,2),\\\n",
    "                         total_voter, round(avg_voter,2)\n",
    "\n",
    "tags_list = [\"Solidity\", \"Web3\", \"Ethereum\", \"Truffle\", \"Security\", \"Metamask\", \"Remix\",\\\n",
    "             \"Ethereum Blockchain\", \"Blockchain\", \"Myetherwallet\", \"Erc20\", \"Token Sale\",\\\n",
    "             \"Cryptocurrency\", \"Bitcoin\", \"Ico\", \"ICO\", \"Programming\", \"Audit\", \"Decentralization\", \"Crypto\"]\n",
    "for tag in tags_list:\n",
    "    a,b,c,d,e,f = resp_clap_voter_1(data, tag)\n",
    "    print(tag, \"-->\", a, \"&\", b, \"&\", c, \"&\", d, \"&\", e, \"&\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Contracts --> 2032 & 2 & 385351 & 294 & 39706 & 30\n",
      "Dapps --> 364 & 2 & 87432 & 424 & 7419 & 36\n",
      "Token --> 492 & 2 & 149770 & 643 & 9303 & 40\n"
     ]
    }
   ],
   "source": [
    "def resp_clap_voter_1(data, tag1, tag2):\n",
    "    new_clap = []\n",
    "    new_voter = []\n",
    "    new_response = []\n",
    "    for key in data:\n",
    "        for i in key['tags']:\n",
    "            if tag1 in i or tag2 in i:\n",
    "                new_clap.append(key['claps'])\n",
    "                new_voter.append(key['voters'])\n",
    "                new_response.append(key['responses'])\n",
    "    \n",
    "    max_response = max(new_response)\n",
    "    total_response = sum(new_response)\n",
    "    avg_response = sum(new_response)/len(new_response)\n",
    "    \n",
    "    max_clap = max(new_clap)\n",
    "    total_clap = sum(new_clap)\n",
    "    avg_clap = sum(new_clap)/len(new_clap)\n",
    "    \n",
    "    max_voter = max(new_voter)\n",
    "    total_voter = sum(new_voter)\n",
    "    avg_voter = sum(new_voter)/len(new_voter)\n",
    "    \n",
    "    return total_response, round(avg_response), total_clap, round(avg_clap),\\\n",
    "                            total_voter, round(avg_voter)\n",
    "\n",
    "tags_list = [[\"Smart Contracts\", \"Smart Contract\"], [\"Dapps\", \"Dapp\"], [\"Token\", \"Tokens\"]]\n",
    "for tags in tags_list:\n",
    "    a,b,c,d,e,f = resp_clap_voter_1(data, tags[0], tags[1])\n",
    "    print(tags[0], \"-->\", a, \"&\", b, \"&\", c, \"&\", d, \"&\", e, \"&\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vulnerability Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "security = 1013\n",
      "vulnerability = 201\n",
      "vulnerab = 466\n",
      "reentrancy = 56\n",
      "re entrancy = 0\n",
      "re-entrancy = 26\n",
      "race condition = 26\n",
      "denial of service = 18\n",
      "DoS = 54\n",
      "transaction order = 13\n",
      "transactions order = 0\n",
      "trasaction order depend = 0\n",
      "transaction-ordering dependence = 7\n",
      "timestamp dependence = 14\n",
      "integer overflow = 50\n",
      "integer underflow = 8\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../conference_medium_data/new_data/related_data_rm_duplicacy_conf_final_2.json\") as f:\n",
    "    post_data = json.load(f)\n",
    "\n",
    "word_list = [\"security\", \"vulnerability\", \"vulnerab\", \"reentrancy\", \"re entrancy\", \"re-entrancy\", \"race condition\",\\\n",
    "             \"denial of service\", \"DoS\", \"transaction order\", \"transactions order\", \"trasaction order depend\",\\\n",
    "             \"transaction-ordering dependence\", \"timestamp dependence\", \"integer overflow\", \"integer underflow\"]\n",
    "# word_list = [\"transaction order\"]\n",
    "for i in word_list:\n",
    "    count = 0\n",
    "    for key in post_data:\n",
    "        if i in key['content'] or i in key['title'].lower() or i in key['tags']:\n",
    "            count += 1\n",
    "            # print(key['title'])\n",
    "    print(i, \"=\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mention of Individual tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mythril = 46\n",
      "mythx = 22\n",
      "mythos = 4\n",
      "oyente = 52\n",
      "solhint = 29\n",
      "solium = 24\n",
      "ethlint = 5\n",
      "securify = 36\n",
      "teether = 2\n",
      "smartcheck = 46\n",
      "manticore = 15\n",
      "sonarsolidity = 0\n",
      "ethir = 2\n",
      "maian = 2\n",
      "solcheck = 4\n",
      "solgraph = 6\n",
      "solint = 3\n",
      "vandal = 1\n",
      "contractfuzzer = 1\n",
      "rattle = 2\n",
      "sasc = 2\n",
      "zeus = 1\n",
      "contractlarva = 1\n",
      "echinda = 0\n",
      "ethertrust = 0\n",
      "fsolidm = 0\n",
      "octopus = 3\n",
      "osiris = 0\n",
      "reguard = 0\n",
      "scompile = 31\n",
      "slither = 6\n",
      "surya = 5\n",
      "sūrya = 1\n",
      "verisolid = 1\n",
      "verx = 0\n",
      "vultron = 0\n",
      "checks-effects-interactions = 15\n"
     ]
    }
   ],
   "source": [
    "sec_tool_list = [\"mythril\", \"mythx\", \"mythos\", \"oyente\", \"solhint\", \"solium\", \"ethlint\",\\\n",
    "                 \"securify\", \"teether\", \"smartcheck\", \"manticore\", \"sonarsolidity\", \"ethir\",\\\n",
    "                 \"maian\", \"solcheck\", \"solgraph\", \"solint\", \"vandal\", \"contractfuzzer\",\\\n",
    "                 \"rattle\", \"sasc\", \"zeus\", \"contractlarva\", \"echinda\", \"ethertrust\", \"fsolidm\",\\\n",
    "                 \"octopus\", \"osiris\", \"reguard\", \"scompile\", \"slither\", \"surya\", \"sūrya\", \"verisolid\",\\\n",
    "                 \"verx\", \"vultron\", \"checks-effects-interactions\"]\n",
    "def tool_mention(data, tool):\n",
    "    count = 0\n",
    "    for key in post_data:\n",
    "        if tool in key['content'].lower() or i in key['title'].lower() or i in key['tags']:\n",
    "            count += 1\n",
    "            # print(key['title'])\n",
    "    print(tool, \"=\", count)\n",
    "    \n",
    "for i in sec_tool_list:\n",
    "    tool_mention(post_data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mythril = 4\n",
      "mythx = 12\n",
      "mythos = 0\n",
      "oyente = 2\n",
      "solhint = 1\n",
      "solium = 3\n",
      "ethlint = 0\n",
      "securify = 1\n",
      "teether = 0\n",
      "smartcheck = 1\n",
      "manticore = 0\n",
      "sonarsolidity = 0\n",
      "ethir = 0\n",
      "maian = 1\n",
      "solcheck = 0\n",
      "solgraph = 0\n",
      "solint = 0\n",
      "vandal = 0\n",
      "contractfuzzer = 0\n",
      "rattle = 0\n",
      "sasc = 1\n",
      "zeus = 0\n",
      "contractlarva = 0\n",
      "echinda = 0\n",
      "ethertrust = 0\n",
      "fsolidm = 0\n",
      "octopus = 0\n",
      "osiris = 0\n",
      "reguard = 0\n",
      "scompile = 0\n",
      "slither = 1\n",
      "surya = 0\n",
      "sūrya = 0\n",
      "verisolid = 0\n",
      "verx = 0\n",
      "vultron = 0\n"
     ]
    }
   ],
   "source": [
    "sec_tool_list = [\"mythril\", \"mythx\", \"mythos\", \"oyente\", \"solhint\", \"solium\", \"ethlint\",\\\n",
    "                 \"securify\", \"teether\", \"smartcheck\", \"manticore\", \"sonarsolidity\", \"ethir\",\\\n",
    "                 \"maian\", \"solcheck\", \"solgraph\", \"solint\", \"vandal\", \"contractfuzzer\",\\\n",
    "                 \"rattle\", \"sasc\", \"zeus\", \"contractlarva\", \"echinda\", \"ethertrust\", \"fsolidm\",\\\n",
    "                 \"octopus\", \"osiris\", \"reguard\", \"scompile\", \"slither\", \"surya\", \"sūrya\", \"verisolid\",\\\n",
    "                 \"verx\", \"vultron\"]\n",
    "# sec_tool_list = [\"sūrya\"]\n",
    "for i in sec_tool_list:\n",
    "    count = 0\n",
    "    for key in post_data:\n",
    "        if (i in key['content'].lower() or i in key['title'].lower() or i in key['tags']) \\\n",
    "                            and ((\"transaction ordering dependency\" in key['content'].lower() or i in key['title'].lower())\\\n",
    "                                or (\"transaction-ordering dependency\" in key['content'].lower() or i in key['title'].lower())\\\n",
    "                                or (\"transaction ordering dependent\" in key['content'].lower() or i in key['title'].lower())):\n",
    "                                 #or (\"timestamp-depend\" in key['content'].lower() or i in key['title'].lower())):\n",
    "            count += 1\n",
    "            # print(key['title'])\n",
    "    print(i, \"=\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of mentions of popular tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solidity = 3424\n",
      "goethereum = 0\n",
      "go-ethereum = 14\n",
      "web3 = 1399\n",
      "web3js = 46\n",
      "contract development = 0\n",
      "blockchain = 4190\n",
      "ethereum = 5382\n",
      "truffle = 2244\n",
      "transaction = 2336\n",
      "transactions = 1182\n",
      "remix = 356\n",
      "contract design = 0\n",
      "token = 4361\n",
      "tokens = 3435\n",
      "ether = 1315\n",
      "erc20 = 1628\n",
      "erc-20 = 364\n",
      "metamask = 2088\n",
      "mining = 179\n",
      "mine = 72\n",
      "javascript = 545\n",
      "private blockchain = 0\n",
      "wallet = 1787\n",
      "wallets = 325\n",
      "gas = 1774\n",
      "parity = 221\n",
      "parities = 0\n"
     ]
    }
   ],
   "source": [
    "tags = [\"solidity\", \"goethereum\", \"go-ethereum\", \"web3\", \"web3js\", \"contract development\", \"blockchain\", \"ethereum\", \"truffle\",\\\n",
    "        \"transaction\", \"transactions\", \"remix\", \"contract design\", \"token\", \"tokens\", \"ether\", \"erc20\", \"erc-20\",\\\n",
    "        \"metamask\", \"mining\", \"mine\", \"javascript\", \"private blockchain\", \"wallet\", \"wallets\", \"gas\", \"parity\", \"parities\"]\n",
    "\n",
    "for i in tags:\n",
    "    count = 0\n",
    "    for key in post_data:\n",
    "        counter = Counter(key['content'].lower().split(\" \"))\n",
    "        count += counter[i]\n",
    "            # print(key['title'])\n",
    "    print(i, \"=\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[758, 1245, 598, 113, 46]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../conference_medium_data/new_data/related_data_rm_duplicacy_conf_final_2.json\") as f:\n",
    "    post_data = json.load(f)\n",
    "    \n",
    "read_list = []\n",
    "for key in post_data:\n",
    "    read_list.append(key['readtime'])\n",
    "\n",
    "_0_2 = 0\n",
    "_2_5 = 0\n",
    "_5_10 = 0\n",
    "_10_15 = 0\n",
    "_15 = 0\n",
    "for i in read_list:\n",
    "    i = float(i)\n",
    "    if i<2:\n",
    "        _0_2 += 1\n",
    "    elif i>=2 and i<5:\n",
    "        _2_5 += 1\n",
    "    elif i>=5 and i<10:\n",
    "        _5_10 += 1\n",
    "    elif i>=10 and i<15:\n",
    "        _10_15 += 1\n",
    "    else:\n",
    "        _15 += 1\n",
    "\n",
    "read_count = [_0_2, _2_5, _5_10, _10_15, _15]\n",
    "read_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
